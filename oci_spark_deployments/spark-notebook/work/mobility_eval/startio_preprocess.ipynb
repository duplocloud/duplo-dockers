{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29980d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "     |################################| 9.5 MB 43.0 MB/s            011\n",
      "\u001b[?25hRequirement already satisfied: h3 in /home/centos/.local/lib/python3.6/site-packages (3.7.3)\n",
      "Requirement already satisfied: sqlalchemy in /home/centos/.local/lib/python3.6/site-packages (1.4.35)\n",
      "Requirement already satisfied: boto3 in /home/centos/.local/lib/python3.6/site-packages (1.21.35)\n",
      "Requirement already satisfied: oci in /home/centos/.local/lib/python3.6/site-packages (2.62.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/centos/.local/lib/python3.6/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/centos/.local/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/centos/.local/lib/python3.6/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/centos/.local/lib/python3.6/site-packages (from sqlalchemy) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/centos/.local/lib/python3.6/site-packages (from sqlalchemy) (4.8.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/centos/.local/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/centos/.local/lib/python3.6/site-packages (from boto3) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.35 in /home/centos/.local/lib/python3.6/site-packages (from boto3) (1.24.35)\n",
      "Requirement already satisfied: certifi in /home/centos/.local/lib/python3.6/site-packages (from oci) (2021.10.8)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in /home/centos/.local/lib/python3.6/site-packages (from oci) (1.3.2)\n",
      "Requirement already satisfied: pyOpenSSL<=19.1.0,>=17.5.0 in /home/centos/.local/lib/python3.6/site-packages (from oci) (19.1.0)\n",
      "Requirement already satisfied: cryptography<=3.4.7,>=3.2.1 in /home/centos/.local/lib/python3.6/site-packages (from oci) (3.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3.6/site-packages (from botocore<1.25.0,>=1.24.35->boto3) (1.25.6)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/centos/.local/lib/python3.6/site-packages (from cryptography<=3.4.7,>=3.2.1->oci) (1.15.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/lib/python3.6/site-packages (from pyOpenSSL<=19.1.0,>=17.5.0->oci) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/centos/.local/lib/python3.6/site-packages (from importlib-metadata->sqlalchemy) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/centos/.local/lib/python3.6/site-packages (from importlib-metadata->sqlalchemy) (4.1.1)\n",
      "Requirement already satisfied: pycparser in /home/centos/.local/lib/python3.6/site-packages (from cffi>=1.12->cryptography<=3.4.7,>=3.2.1->oci) (2.21)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas h3 sqlalchemy boto3 oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fcd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '37776'),\n",
       " ('spark.driver.cores', '4'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.scheduler.mode', 'FAIR'),\n",
       " ('spark.cores.max', '16'),\n",
       " ('spark.app.startTime', '1649654815779'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/centos/work/mobility_eval/spark-warehouse'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.executor.memory', '12g'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.app.id', 'app-20220411052657-0002'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host',\n",
       "  'oke-cf2oghpidfa-nt5qvktoxqa-shjnqmwa77q-0.subc6544f31f.useastcluster.oraclevcn.com'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.master', 'spark://10.0.10.62:7077'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"starting...\")\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"part_1_mobility_script_generic(new_dataset)_new (2).ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1dGNHBaJAS1w2hsZw4c_Kx4bFdQ0Kzdg_\n",
    "\"\"\"\n",
    "\n",
    "print(\"starting...\")\n",
    "\n",
    "from pyspark.sql.window import Window \n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, window\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import desc\n",
    "import datetime, time\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from h3 import h3\n",
    "\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from pyspark.sql.functions import lit\n",
    "import json\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    " \n",
    "import oci\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "from pyspark.sql.functions import round, col\n",
    "from dateutil import tz\n",
    "import sqlalchemy as db\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "ociconf = oci.config.from_file()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .config(\"spark.driver.cores\", \"4\") \\\n",
    "        .config(\"spark.executor.memory\", \"12g\") \\\n",
    "        .config(\"spark.executor.cores\", \"4\") \\\n",
    "        .config(\"spark.scheduler.mode\", \"FAIR\") \\\n",
    "        .config(\"spark.cores.max\", \"16\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# spark.conf.set('fs.oci.client.auth.tenantId', ociconf['tenancy'])\n",
    "# spark.conf.set('fs.oci.client.auth.userId',  ociconf['user'])\n",
    "# spark.conf.set('fs.oci.client.auth.fingerprint', ociconf['fingerprint'])\n",
    "# spark.conf.set('fs.oci.client.auth.pemfilepath', \"~/.oci/oci_api_key\")\n",
    "# spark.conf.set('fs.oci.client.auth.tenantId.region', \"us-ashburn-1\")\n",
    "# spark.conf.set('fs.oci.client.hostname', \"https://objectstorage.us-ashburn-1.oraclecloud.com\")\n",
    "\n",
    "spark.conf.set('fs.oci.client.auth.tenantId', \"ocid1.tenancy.oc1..aaaaaaaamqxmfclvmrazpk4kt7ibkcfzfg2fvg4o2wyzemzu3n7tcpf6nvsa\")\n",
    "spark.conf.set('fs.oci.client.auth.userId', \"ocid1.user.oc1..aaaaaaaa4gjumyz4kiowhzbyjzgajyo5bln565rntgboqod3t6lu4bpwl2ra\")\n",
    "spark.conf.set('fs.oci.client.auth.fingerprint', \"ec:8f:0e:14:e0:31:cd:e4:d6:03:04:aa:aa:94:f9:a9\")\n",
    "spark.conf.set('fs.oci.client.auth.pemfilepath', \"~/.oci/oci_api_key\")\n",
    "spark.conf.set('fs.oci.client.auth.tenantId.region', \"us-ashburn-1\")\n",
    "spark.conf.set('fs.oci.client.hostname', \"https://objectstorage.us-ashburn-1.oraclecloud.com\")\n",
    "\n",
    "# spark.driver.cores\n",
    "# spark.driver.memory\n",
    "# spark.driver.memoryOverhead\n",
    "# spark.executor.memory = 1g\n",
    "# spark.executor.memoryOverhead\n",
    "# spark.driver.resource.{resourceName}.amount\n",
    "# spark.executor.resource.{resourceName}.amount\n",
    "# spark.executor.cores\n",
    "spark.sparkContext._conf.getAll()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8fcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window \n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "import datetime, time\n",
    "import datetime as dt\n",
    "#import pyproj\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "# spark.conf.set(\"spark.sql.session.timeZone\", \"GMT\")\n",
    "\n",
    "from h3 import h3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string = f\"oci://mobility-data@bmmp5bv7olp2/usa/startapp/location/20220328\"\n",
    "df = spark.read.format(\"csv\").load(save_string, header = 'false')\n",
    "\n",
    "cols = ['AAID',  'longitude', \"latitude\", \"accuracy\", \"timestamp\",\"source\", \"IP\"]\n",
    "df = df.toDF(*cols)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "country =  \"US\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eacf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "base = datetime.date(2022, 2,20)\n",
    "date_list = [base + datetime.timedelta(days=x) for x in range(8)]\n",
    "dates = [datetime.datetime.strftime(x,\"%Y-%m-%d\") for x in date_list]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138904e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
