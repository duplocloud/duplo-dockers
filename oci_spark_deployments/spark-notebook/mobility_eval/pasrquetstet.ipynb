{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261a82a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init --- diff-total: 0 , diffstep: 0 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:08 , end_step: 2022-05-27 20:30:08\n"
     ]
    }
   ],
   "source": [
    "import time  \n",
    "start = time.time()\n",
    "prevstep = time.time()\n",
    "def frmDate(now):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(now)) \n",
    "\n",
    "def logDiff(mesage):\n",
    "    global prevstep\n",
    "    end = time.time()\n",
    "    diff = int(end - start)\n",
    "    diffstep = int(end - prevstep)\n",
    "    prevstep = end\n",
    "    print(mesage,\"--- diff-total:\", diff, \",\", \\\n",
    "          \"diffstep:\", diffstep, \",\" , \\\n",
    "          \"start:\", frmDate(start), \",\" , \\\n",
    "          \"start_step:\",  frmDate(prevstep), \",\" , \\\n",
    "          \"end_step:\", frmDate(end))\n",
    "logDiff(\"init\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24f1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/centos/.local/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: h3 in /home/centos/.local/lib/python3.8/site-packages (3.7.4)\n",
      "Requirement already satisfied: sqlalchemy in /home/centos/.local/lib/python3.8/site-packages (1.4.36)\n",
      "Requirement already satisfied: boto3 in /home/centos/.local/lib/python3.8/site-packages (1.23.9)\n",
      "Requirement already satisfied: oci in /home/centos/.local/lib/python3.8/site-packages (2.69.0)\n",
      "Requirement already satisfied: delta-spark in /home/centos/.local/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: IPython in /home/centos/.local/lib/python3.8/site-packages (8.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/centos/.local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/centos/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/centos/.local/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/centos/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/centos/.local/lib/python3.8/site-packages (from sqlalchemy) (1.1.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/centos/.local/lib/python3.8/site-packages (from boto3) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/centos/.local/lib/python3.8/site-packages (from boto3) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.9 in /home/centos/.local/lib/python3.8/site-packages (from boto3) (1.26.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/centos/.local/lib/python3.8/site-packages (from botocore<1.27.0,>=1.26.9->boto3) (1.26.9)\n",
      "Requirement already satisfied: pyOpenSSL<=19.1.0,>=17.5.0 in /home/centos/.local/lib/python3.8/site-packages (from oci) (19.1.0)\n",
      "Requirement already satisfied: cryptography<=3.4.7,>=3.2.1 in /home/centos/.local/lib/python3.8/site-packages (from oci) (3.4.7)\n",
      "Requirement already satisfied: certifi in /home/centos/.local/lib/python3.8/site-packages (from oci) (2022.5.18.1)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in /home/centos/.local/lib/python3.8/site-packages (from oci) (1.3.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/centos/.local/lib/python3.8/site-packages (from cryptography<=3.4.7,>=3.2.1->oci) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/centos/.local/lib/python3.8/site-packages (from cffi>=1.12->cryptography<=3.4.7,>=3.2.1->oci) (2.21)\n",
      "Requirement already satisfied: pyspark<3.3.0,>=3.2.0 in /home/centos/.local/lib/python3.8/site-packages (from delta-spark) (3.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /home/centos/.local/lib/python3.8/site-packages (from delta-spark) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/centos/.local/lib/python3.8/site-packages (from importlib-metadata>=1.0.0->delta-spark) (3.8.0)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in /home/centos/.local/lib/python3.8/site-packages (from pyspark<3.3.0,>=3.2.0->delta-spark) (0.10.9.3)\n",
      "Requirement already satisfied: matplotlib-inline in /home/centos/.local/lib/python3.8/site-packages (from IPython) (0.1.3)\n",
      "Requirement already satisfied: backcall in /home/centos/.local/lib/python3.8/site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/centos/.local/lib/python3.8/site-packages (from IPython) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/centos/.local/lib/python3.8/site-packages (from IPython) (3.0.29)\n",
      "Requirement already satisfied: decorator in /home/centos/.local/lib/python3.8/site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/centos/.local/lib/python3.8/site-packages (from IPython) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/centos/.local/lib/python3.8/site-packages (from IPython) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /home/centos/.local/lib/python3.8/site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/python3/lib/python3.8/site-packages (from IPython) (56.0.0)\n",
      "Requirement already satisfied: traitlets>=5 in /home/centos/.local/lib/python3.8/site-packages (from IPython) (5.2.1.post0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/centos/.local/lib/python3.8/site-packages (from IPython) (2.12.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/centos/.local/lib/python3.8/site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/centos/.local/lib/python3.8/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/centos/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in /home/centos/.local/lib/python3.8/site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/centos/.local/lib/python3.8/site-packages (from stack-data->IPython) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/centos/.local/lib/python3.8/site-packages (from stack-data->IPython) (2.0.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas h3 sqlalchemy boto3 oci delta-spark IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a34995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/27 20:30:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/27 20:30:14 WARN FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparkContext --- diff-total: 8 , diffstep: 8 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:16 , end_step: 2022-05-27 20:30:16\n"
     ]
    }
   ],
   "source": [
    "print(\"starting...\")\n",
    "\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"part_1_mobility_script_generic(new_dataset)_new (2).ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1dGNHBaJAS1w2hsZw4c_Kx4bFdQ0Kzdg_\n",
    "\"\"\"\n",
    "\n",
    "print(\"starting...\")\n",
    "\n",
    "from pyspark.sql.window import Window \n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, window\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import desc\n",
    "import datetime, time\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from h3 import h3\n",
    "\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from pyspark.sql.functions import lit\n",
    "import json\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    " \n",
    "import oci\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "from pyspark.sql.functions import round, col\n",
    "from dateutil import tz\n",
    "import sqlalchemy as db\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "ociconf = oci.config.from_file()\n",
    "from pyspark.sql.functions import broadcast\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "# new\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf, SparkContext \n",
    "\n",
    "# .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.1.0\") \\\n",
    "# .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "# .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "# # config for 88 executor  -- change executor  count slaves 11=8c64g  11*8==88 cores, 11 * 64=704\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.driver.memory\", \"64g\") \\\n",
    "        .config(\"spark.driver.cores\", \"8\") \\\n",
    "        .config(\"spark.executor.memory\", \"64g\") \\\n",
    "        .config(\"spark.executor.cores\", \"8\") \\\n",
    "        .config(\"spark.scheduler.mode\", \"FAIR\") \\\n",
    "        .config(\"spark.cores.max\", \"8\") \\\n",
    "        .config(\"spark.delta.logStore.oci.impl\",\"io.delta.storage.OracleCloudLogStore\") \\\n",
    "        .getOrCreate() \n",
    "#.config(\"spark.executor.instances\", \"10\")\n",
    "spark.conf.set('fs.oci.client.auth.tenantId', \"ocid1.tenancy.oc1..aaaaaaaamqxmfclvmrazpk4kt7ibkcfzfg2fvg4o2wyzemzu3n7tcpf6nvsa\")\n",
    "spark.conf.set('fs.oci.client.auth.userId', \"ocid1.user.oc1..aaaaaaaa4gjumyz4kiowhzbyjzgajyo5bln565rntgboqod3t6lu4bpwl2ra\")\n",
    "spark.conf.set('fs.oci.client.auth.fingerprint', \"ec:8f:0e:14:e0:31:cd:e4:d6:03:04:aa:aa:94:f9:a9\")\n",
    "spark.conf.set('fs.oci.client.auth.pemfilepath', \"~/.oci/oci_api_key\")\n",
    "spark.conf.set('fs.oci.client.auth.tenantId.region', \"us-ashburn-1\")\n",
    "spark.conf.set('fs.oci.client.hostname', \"https://objectstorage.us-ashburn-1.oraclecloud.com\")\n",
    "\n",
    "# new sql \n",
    "# spark = SQLContext(spark.sparkContext)\n",
    "## register data frame as a temporary table\n",
    "# orders_df.registerTempTable(\"orders\")\n",
    "\n",
    "spark.sparkContext._conf.getAll()\n",
    "logDiff(\"sparkContext\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d390b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df=spark.createDataFrame(data,columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0515f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|   James |          |   Smith|36636|     M|  3000|\n",
      "| Michael |      Rose|        |40288|     M|  4000|\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "show df --- diff-total: 12 , diffstep: 4 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:20 , end_step: 2022-05-27 20:30:20\n",
      "--- 2.5845351219177246 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df.show(3)\n",
    "logDiff(\"show df\") \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d286ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 20:30:22 WARN RestClient: Stream size to upload is 0 bytes, this could potentially lead to data corruption. If this is not intended, please make sure all the OCI SDK dependencies point to the same version\n",
      "22/05/27 20:30:23 WARN RestClient: Stream size to upload is 0 bytes, this could potentially lead to data corruption. If this is not intended, please make sure all the OCI SDK dependencies point to the same version\n",
      "[Stage 5:==========================================>              (37 + 8) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.466702699661255 seconds ---\n",
      "save df --- diff-total: 25 , diffstep: 13 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:33 , end_step: 2022-05-27 20:30:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "delta_file=\"oci://mobility-data@bmmp5bv7olp2/ind/lifesight/silver_layer_city/test_delta1/\"\n",
    "df.write.format('delta').mode(\"overwrite\") \\\n",
    ".save(delta_file)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "logDiff(\"save df\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd6ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 20:30:34 WARN RestClient: Stream size to upload is 0 bytes, this could potentially lead to data corruption. If this is not intended, please make sure all the OCI SDK dependencies point to the same version\n",
      "22/05/27 20:30:34 WARN RestClient: Stream size to upload is 0 bytes, this could potentially lead to data corruption. If this is not intended, please make sure all the OCI SDK dependencies point to the same version\n",
      "22/05/27 20:30:34 WARN RestClient: Stream size to upload is 0 bytes, this could potentially lead to data corruption. If this is not intended, please make sure all the OCI SDK dependencies point to the same version\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.1383490562438965 seconds ---\n",
      "save df --- diff-total: 28 , diffstep: 3 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:37 , end_step: 2022-05-27 20:30:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/27 20:30:36 WARN RestClient: Stream size to upload is 0 bytes, this could potentially lead to data corruption. If this is not intended, please make sure all the OCI SDK dependencies point to the same version\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "parquet_file=\"oci://mobility-data@bmmp5bv7olp2/ind/lifesight/silver_layer_city/test_paruquet3/\"\n",
    "df.write.format('parquet').mode(\"overwrite\") \\\n",
    ".save(parquet_file)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "logDiff(\"save df\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c57c863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load block_df --- diff-total: 29 , diffstep: 0 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:37 , end_step: 2022-05-27 20:30:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "read_df = spark.read.format(\"delta\").load(delta_file, header = 'true')\n",
    "logDiff(\"load block_df\") \n",
    "read_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbee416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load block_df --- diff-total: 31 , diffstep: 2 , start: 2022-05-27 20:30:08 , start_step: 2022-05-27 20:30:39 , end_step: 2022-05-27 20:30:39\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_df = spark.read.format(\"parquet\").load(parquet_file, header = 'true')\n",
    "logDiff(\"load block_df\") \n",
    "read_df.show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
