{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e42ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161fded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select 'spark' as hello \")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e436daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: long (nullable = true)\n",
      "\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  1|   10|\n",
      "|  2|   14|\n",
      "|  3|   17|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = [[1,10],[2,14],[3,17]]\n",
    "df = spark.createDataFrame(data=x, schema = [\"id\",\"value\"])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdbb011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|numbers|\n",
      "+---+-------+\n",
      "|abc| [1, 2]|\n",
      "| cd| [3, 4]|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "rdd = spark.sparkContext.parallelize(\n",
    "    [Row(\"abc\", [1, 2]), Row(\"cd\", [3, 4])]\n",
    ")\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"numbers\", ArrayType(IntegerType(), True), True)\n",
    "])\n",
    "df = spark.createDataFrame(rdd, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1887eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|num1|num2|\n",
      "+----+----+\n",
      "|  33|  44|\n",
      "|  55|  66|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(33, 44), (55, 66)], [\"num1\", \"num2\"]\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89b30e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+\n",
      "|num1|num2|    nums|\n",
      "+----+----+--------+\n",
      "|  33|  44|[33, 44]|\n",
      "|  55|  66|[55, 66]|\n",
      "+----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"nums\", array(df.num1, df.num2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fab32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|first_name| color|\n",
      "+----------+------+\n",
      "|       joe|   red|\n",
      "|       joe|  blue|\n",
      "|      lisa|yellow|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"joe\", \"red\"), (\"joe\", \"blue\"), (\"lisa\", \"yellow\")], [\"first_name\", \"color\"]\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3040fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|first_name|     colors|\n",
      "+----------+-----------+\n",
      "|      lisa|   [yellow]|\n",
      "|       joe|[red, blue]|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = (df\n",
    "    .groupBy(df.first_name)\n",
    "    .agg(collect_list(col(\"color\")).alias(\"colors\")))\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32159cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- colors: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae426ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|numbers|\n",
      "+---+-------+\n",
      "|abc| [1, 2]|\n",
      "| cd| [3, 4]|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(\"abc\", [1, 2]), (\"cd\", [3, 4])], [\"id\", \"numbers\"]\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d21ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|number|\n",
      "+---+------+\n",
      "|abc|     1|\n",
      "|abc|     2|\n",
      "| cd|     3|\n",
      "| cd|     4|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"id\"), explode(col(\"numbers\")).alias(\"number\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66bacfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languagesAtWork: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      " |-- previousState: string (nullable = true)\n",
      "\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|            name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|\n",
      "+----------------+------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [\n",
    " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
    " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
    " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
    "]\n",
    "\n",
    "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
    "schema = StructType([ \n",
    "    StructField(\"name\",StringType(),True), \n",
    "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True), \n",
    "    StructField(\"languagesAtWork\",ArrayType(StringType()),True), \n",
    "    StructField(\"currentState\", StringType(), True), \n",
    "    StructField(\"previousState\", StringType(), True)\n",
    "  ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d533faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|            name|   col|\n",
      "+----------------+------+\n",
      "|    James,,Smith|  Java|\n",
      "|    James,,Smith| Scala|\n",
      "|    James,,Smith|   C++|\n",
      "|   Michael,Rose,| Spark|\n",
      "|   Michael,Rose,|  Java|\n",
      "|   Michael,Rose,|   C++|\n",
      "|Robert,,Williams|CSharp|\n",
      "|Robert,,Williams|    VB|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name,explode(df.languagesAtSchool)).show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5dae519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         nameAsArray|\n",
      "+--------------------+\n",
      "|    [James, , Smith]|\n",
      "|   [Michael, Rose, ]|\n",
      "|[Robert, , Williams]|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import split\n",
    "df.select(split(df.name,\",\").alias(\"nameAsArray\")).show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13e457f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|            name|  States|\n",
      "+----------------+--------+\n",
      "|    James,,Smith|[OH, CA]|\n",
      "|   Michael,Rose,|[NY, NJ]|\n",
      "|Robert,,Williams|[UT, NV]|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import array\n",
    "df.select(df.name,array(df.currentState,df.previousState).alias(\"States\")).show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3131a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+\n",
      "|            name|array_contains|\n",
      "+----------------+--------------+\n",
      "|    James,,Smith|          true|\n",
      "|   Michael,Rose,|          true|\n",
      "|Robert,,Williams|         false|\n",
      "+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.select(df.name,array_contains(df.languagesAtSchool,\"Java\")\n",
    "    .alias(\"array_contains\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba295a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
